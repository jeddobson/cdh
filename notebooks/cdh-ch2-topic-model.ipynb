{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk version:  3.2.2\n",
      "sklearn version:  0.18.1\n"
     ]
    }
   ],
   "source": [
    "# local Natural Language Toolkit\n",
    "import nltk\n",
    "print(\"nltk version: \",nltk.__version__)\n",
    "\n",
    "# load scikit-learn \n",
    "import sklearn\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "print(\"sklearn version: \",sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading files and loading into vectorizer\n",
      "Topic #0:\n",
      "adams,henry,minister,felt,john,washington,young,hay,came,saw,went,point,took,wanted,long,war,century,reason,president,know\n",
      "\n",
      "Topic #1:\n",
      "education,henry,point,social,far,political,history,politics,best,value,took,study,long,went,wanted,private,washington,secretary,order,college\n",
      "\n",
      "Topic #2:\n",
      "years,london,england,study,known,end,europe,work,boy,long,college,great,power,student,value,washington,private,secretary,war,father\n",
      "\n",
      "Topic #3:\n",
      "man,young,nature,power,secretary,far,known,matter,private,science,washington,boy,student,idea,energy,sense,better,work,house,history\n",
      "\n",
      "Topic #4:\n",
      "thought,good,english,nature,minister,history,unity,henry,called,century,matter,great,london,best,science,boy,came,people,better,secretary\n",
      "\n",
      "Topic #5:\n",
      "like,power,century,hay,politics,friends,great,energy,history,best,far,private,sumner,said,day,secretary,boston,europe,social,reason\n",
      "\n",
      "Topic #6:\n",
      "new,england,forces,power,great,social,idea,needed,nature,make,boston,went,house,washington,law,america,president,hay,school,work\n",
      "\n",
      "Topic #7:\n",
      "knew,better,far,secretary,good,private,known,history,boy,way,friends,political,hay,value,college,point,power,people,sumner,london\n",
      "\n",
      "Topic #8:\n",
      "american,minister,young,history,people,felt,century,saw,home,day,england,idea,government,boy,long,came,father,moment,best,wanted\n",
      "\n",
      "Topic #9:\n",
      "life,long,great,far,boy,end,power,friends,matter,better,known,took,law,england,street,nature,work,century,felt,wanted\n",
      "\n",
      "Topic #10:\n",
      "mind,felt,english,nature,boston,long,boy,took,history,make,forces,way,century,social,law,far,matter,father,order,energy\n",
      "\n",
      "Topic #11:\n",
      "time,felt,russell,great,hay,sense,value,led,young,needed,england,far,law,history,president,know,power,boston,state,came\n",
      "\n",
      "Topic #12:\n",
      "society,london,english,law,social,washington,boston,century,went,power,reason,science,led,home,long,better,moment,called,government,saw\n",
      "\n",
      "Topic #13:\n",
      "world,power,great,washington,saw,felt,europe,point,way,year,best,far,boy,hay,president,took,england,quite,private,reason\n",
      "\n",
      "Topic #14:\n",
      "did,know,great,boston,better,good,russell,hay,work,government,far,secretary,wanted,matter,minister,reason,nature,make,law,sense\n",
      "\n",
      "Topic #15:\n",
      "little,felt,history,saw,century,personal,took,boy,make,good,hay,needed,political,college,student,best,house,friends,better,study\n",
      "\n",
      "Topic #16:\n",
      "force,felt,nature,forces,science,russell,moment,energy,known,secretary,power,personal,unity,private,work,political,palmerston,led,self,lord\n",
      "\n",
      "Topic #17:\n",
      "men,young,great,felt,forces,came,history,quite,went,best,self,washington,friends,science,way,work,america,political,law,value\n",
      "\n",
      "Topic #18:\n",
      "old,year,president,felt,century,house,boy,took,boston,quite,science,point,lord,europe,father,state,hay,friends,self,henry\n",
      "\n",
      "Topic #19:\n",
      "mr,sumner,secretary,russell,private,took,president,far,said,house,boston,palmerston,washington,state,lord,social,came,personal,went,led\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('reading files and loading into vectorizer')\n",
    "\n",
    "# make explicit default flags and parameters\n",
    "vectorizer = text.CountVectorizer(input=input,lowercase='true',max_features=100, \n",
    "                                  strip_accents='unicode',\n",
    "                                  stop_words='english')\n",
    "\n",
    "# replace text that the vectorizer cannot read\n",
    "vectorizer.decode_error='replace'\n",
    "counts = vectorizer.fit_transform(input)\n",
    "tfidf = text.TfidfTransformer().fit_transform(counts)\n",
    "\n",
    "# fit to model\n",
    "nmf = decomposition.NMF(n_components=20).fit(tfidf)\n",
    "\n",
    "# extract topics \n",
    "feature_names = vectorizer.get_feature_names()\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    print(\",\".join([feature_names[i]\n",
    "    for i in topic.argsort()[:-20 - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fstream = open(\"eduha10.txt\",encoding='utf-8')\n",
    "print('reading files and loading into vectorizer')\n",
    "\n",
    "# make explicit default flags and parameters\n",
    "vectorizer = text.CountVectorizer(input=fstream,ngram_range=(2,4),\n",
    "                                  lowercase='true',max_features=100, \n",
    "                                  strip_accents='unicode',\n",
    "                                  stop_words='english')\n",
    "\n",
    "# replace text that the vectorizer cannot read\n",
    "vectorizer.decode_error='replace'\n",
    "counts = vectorizer.fit_transform(fstream)\n",
    "tfidf = text.TfidfTransformer().fit_transform(counts)\n",
    "\n",
    "# fit to model\n",
    "nmf = decomposition.NMF(n_components=20).fit(tfidf)\n",
    "\n",
    "# extract topics \n",
    "feature_names = vectorizer.get_feature_names()\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    print(\",\".join([feature_names[i]\n",
    "    for i in topic.argsort()[:-20 - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
